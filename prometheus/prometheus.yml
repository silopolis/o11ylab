# Global config
global:
  # How often to scrape targets by default (override per-job later).
  scrape_interval: 15s
  # Give scrapes time to finish without overlapping.
  scrape_timeout: 10s
  # How often to evaluate recording/alerting rules.
  evaluation_interval: 15s

  # Propagate identity to any remote systems (Thanos/Mimir/Cortex/victoriametrics/etc.)
  # Used for clean HA deduplication of time series and global routing in remote backends.
  # Ensure "replica" is unique per Prometheus instance in the same HA pair.
  external_labels:
    environment: "dev"
    cluster: "lab"
    region: "local"
    replica: "prom-0"

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
      - targets:
        #- alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
# Keep recording rules even if you're deferring alerting; they cut query costs
# and stabilize dashboards under load. Point at a directory you control.
# recording rules reduce cardinality and CPU pressure for heavy dashboard queries
# create high-value aggregations (e.g., per-service rates, SLO windows) so dashboards/alerts donâ€™t
# stress the TSDB at query time.
# Load *recording rules* first; add alerting rules later in separate files.
# Keep rule files small and focused; use globs to allow easy additions.
rule_files:
  - rules/recording/*.rules.yml
  - rules/alerting/*.rules.yml

scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  # -- Prometheus itself.
  # Ingest own /metrics so you can build SLO/SLA views, capacity dashboards (TSDB, WAL, head block),
  # and query health stats.
  - job_name: "prometheus"
    honor_labels: true
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
      - targets: ["localhost:9090"]
        # The label name is added as a label `label_name=<label_value>` to any timeseries scraped from this config.
        labels:
          service: "prometheus"
          component: "tsdb"

  - job_name: 'blackbox_exporter'  # collect blackbox exporter's operational metrics.
    honor_labels: true
    static_configs:
      - targets: ['blackbox:9115']
        labels:
          service: "prometheus"
          component: "blackbox"

  # --- Readiness probe: GET /-/ready must return HTTP 200
  - job_name: "blackbox-prom-ready"
    metrics_path: /probe
    scrape_interval: 15s
    scrape_timeout: 10s
    params:
      module: [http_200]   # refers to blackbox.yml module name
    static_configs:
      - targets:
          # Probe the readiness endpoint exposed by Prometheus
          - "http://prometheus:9090/-/ready"
        labels:
          service: "prometheus"
          probe: "ready"
    relabel_configs:
      # Pass the real target URL to the blackbox exporter as the 'target' param
      - source_labels: [__address__]
        target_label: __param_target
      # Preserve the probed URL as a label on the resulting metrics
      - source_labels: [__param_target]
        target_label: instance            # the *URL* we are probing
      # Tell Prometheus to scrape the blackbox exporter itself (wherever it runs)
      - target_label: __address__
        replacement: "blackbox:9115"        # send the probe to blackbox

  # --- Query API probe: GET /api/v1/query?query=1 should be a successful JSON response
  - job_name: "blackbox-prom-query"
    metrics_path: /probe
    scrape_interval: 30s
    scrape_timeout: 10s
    sample_limit: 100
    params:
      module: [prom_instant_query]  # defined in blackbox config
    static_configs:
      - targets:
          - "http://prometheus:9090/api/v1/query?query=1"
        labels:
          service: "prometheus"
          probe: "query_api"
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: "blackbox:9115"

scrape_config_files:
- scrape_configs/*.scrape.yml

